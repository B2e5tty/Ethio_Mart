{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import importlib\n",
    "import asyncio\n",
    "import re\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join('..','src')))\n",
    "\n",
    "\n",
    "import data_collection as dc\n",
    "importlib.reload(dc)\n",
    "\n",
    "import tokenization as tk\n",
    "importlib.reload(tk)\n",
    "\n",
    "import nltk\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting data from the telegram channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# await dc.main_def()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   Channel Title     500 non-null    object\n",
      " 1   Channel Username  500 non-null    object\n",
      " 2   ID                500 non-null    int64 \n",
      " 3   Message           133 non-null    object\n",
      " 4   Date              500 non-null    object\n",
      " 5   Media Path        483 non-null    object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 23.6+ KB\n",
      "The shape of the dataframe after dropping NaN values: (133, 6)\n"
     ]
    }
   ],
   "source": [
    "# import the data for cleaning\n",
    "tok = tk.Tokenization('telegram_data.csv')\n",
    "\n",
    "# clean the dataframe\n",
    "tok.clean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove emjois and save cleaned data\n",
    "tok.remove_emojis()    # clean_message.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize each message\n",
    "tok = tk.Tokenization('clean_message.csv')\n",
    "# tokens = \n",
    "tok.new_tokenization()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Assigning the labels to the token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13405 entries, 0 to 13404\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   word    13405 non-null  object\n",
      " 1   label   13405 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 209.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# tokens and their lables\n",
    "new_tokens, new_labels = tok.new_label_tokens()\n",
    "\n",
    "# to dataframe\n",
    "label_tokens = pd.DataFrame({'word':new_tokens,'label':new_labels})\n",
    "\n",
    "# remove and replace english words\n",
    "label_tokens_df = tok.remove_english_word(label_tokens)\n",
    "label_tokens_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CoNLL Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CoNLL format (with space as separator)\n",
    "tok.conll_format(label_tokens_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
